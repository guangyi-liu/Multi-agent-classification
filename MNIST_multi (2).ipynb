{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the main code for training and testing. This code is modified from the previous work of our group, names are omitted.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch \n",
    "import copy\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.distributions import Categorical \n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib\n",
    "import matplotlib.backends\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc, colors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "#fcns for print and get_time\n",
    "import fcn as fcn\n",
    "from skimage.util import view_as_windows\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in ('true', '1')\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\")\n",
    "\n",
    "# You may choose the number of robots and the operation time in here\n",
    "parser.add_argument('--n_rollouts', default=1,type=int, help=\"\")\n",
    "parser.add_argument('--random_seed', default=666662222,type=int, help=\"\")\n",
    "parser.add_argument('--time_h', default=8,type=int, help=\"\")\n",
    "parser.add_argument('--f_size', default=4,type=int, help=\"\")\n",
    "parser.add_argument('--n_agent', default=4,type=int, help=\"\")\n",
    "\n",
    "parser.add_argument('--log_dir', type=str, default='logsmnist')\n",
    "parser.add_argument('--gpu', type=int, default=3)\n",
    "parser.add_argument('--stdout_print', default=True, type=str2bool, help='print control')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "args = vars(args)\n",
    "\n",
    "args['log_dir'] = \"{}\".format(args['log_dir'])\n",
    "try:\n",
    "    os.makedirs(args['log_dir'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# select your cuda number\n",
    "device = torch.device(\"cuda:3\" if use_cuda else \"cpu\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import *\n",
    "\n",
    "from mnist_penalty_comm import CModel\n",
    "from mnist_penalty_comm import Actor\n",
    "from mnist_penalty_comm import EnvMNIST\n",
    "from mnist_penalty_comm import MnistAgent\n",
    "\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "bsize = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please select the apporiate batch_size based on your cuda memory\n",
    "\n",
    "trainloader = DataLoader(train_set, batch_size=bsize, shuffle=True)\n",
    "testloader = DataLoader(test_set, batch_size=bsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_seed': 666662222, 'f_size': 4, 'stdout_print': True, 'log_dir': 'logsmnist', 'gpu': 3, 'n_agent': 4, 'time_h': 8, 'n_rollouts': 1}\n"
     ]
    }
   ],
   "source": [
    "# Please select the apporiate batch_size based on your cuda memory\n",
    "\n",
    "batch_size = bsize\n",
    "f_size=args['f_size']\n",
    "n_agent=args['n_agent']\n",
    "n_rollouts=args['n_rollouts'] # 2\n",
    "prog_print=True\n",
    "prog_percent=98\n",
    "time_h=args['time_h']\n",
    "seed=args['random_seed']\n",
    "single_train = False\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "vggm = vgg.vgg19(pretrained=True).to(device)\n",
    "vggm.classifier[6] = nn.Linear(vggm.classifier[6].in_features, 8).to(device)\n",
    "\n",
    "for param in vggm.features.parameters():\n",
    "    param.requires_grad = False\n",
    "print(vggm.classifier[6].out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.classifier.0.weight\n",
      "model.classifier.0.bias\n",
      "model.classifier.3.weight\n",
      "model.classifier.3.bias\n",
      "model.classifier.6.weight\n",
      "model.classifier.6.bias\n",
      "lstm.weight_ih\n",
      "lstm.weight_hh\n",
      "lstm.bias_ih\n",
      "lstm.bias_hh\n",
      "lstmf1.weight_ih\n",
      "lstmf1.weight_hh\n",
      "lstmf1.bias_ih\n",
      "lstmf1.bias_hh\n",
      "pred.weight\n",
      "pred.bias\n",
      "gn1.weight\n",
      "gn1.bias\n",
      "gn2.weight\n",
      "gn2.bias\n",
      "gp.weight\n",
      "gp.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object parameters at 0x7fa4775dc2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= CModel(HD=32, frame_size=f_size, n_agent=n_agent, _msg_dim=12, device=device, random_action_flag=False,no_channels=3,edge_pr=1,\\\n",
    "                              kern_size=1,model = vggm).to(device) # HD=64\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist_penalty_comm.py:489: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  x = (torch.range(0, h-1)-(filter_size-1)/2.0)/((filter_size-1)/2.0)\n",
      "mnist_penalty_comm.py:490: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  y = (torch.range(0, w-1)-(filter_size-1)/2.0)/((filter_size-1)/2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mnist_penalty_comm.py:156: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  x= torch.stack(mu_goal.shape[0]*[torch.range(0,self.maxDim)],0).to(self.device)\n",
      "mnist_penalty_comm.py:157: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  y=torch.stack(mu_goal.shape[0]*[torch.range(0,self.maxDim)],0).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, target) in enumerate(trainloader):\n",
    "#     print(target)\n",
    "    break\n",
    "    \n",
    "for batch_idx, (x, target) in enumerate(trainloader):\n",
    "#     print(target)\n",
    "    break\n",
    "    \n",
    "def train(eps, optimizer, criterion):\n",
    "        \n",
    "    train_cnt = 0    \n",
    "    best_accuracy = 0\n",
    "    best_accuracy_train=0\n",
    "    test_acc_lst = []\n",
    "    old = datetime.now()\n",
    "    l_accuracy = 0\n",
    "    \n",
    "    for epochs in xrange(eps):\n",
    "        print(epochs)\n",
    "        \n",
    "#         It's recommended to save the model using the following  command\n",
    "#         torch.save(model.state_dict(), 'mnist_multi.pt')\n",
    "\n",
    "        for traininput, trainlabel in trainloader:\n",
    "            x, target = traininput.to(device), trainlabel.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            val=-actor.multi_rollout(x.to(device),target.to(device),n_rollouts)\n",
    "            loss = val \n",
    "            loss.backward()\n",
    "            optimizer.step() #(closure)\n",
    "            with torch.no_grad():\n",
    "                # the constraint for training\n",
    "                max_inf_f = model.inf_f\n",
    "                # inf norms of the LSTM Wo\n",
    "                Wo = model.lstm.weight_hh[192:256]\n",
    "                Wo_inf = torch.norm(Wo,p=1,dim=1)\n",
    "                inf_Wo = torch.max(Wo_inf)\n",
    "\n",
    "                if inf_Wo.data.cpu().numpy() >= (1-max_inf_f):\n",
    "                    model.lstm.weight_hh[192:256] = model.lstm.weight_hh[192:256].clone()/1.2\n",
    "\n",
    "                # inf norms of the LSTM Wi\n",
    "                Wi = model.lstm.weight_hh[0:64]\n",
    "                Wi_inf = torch.norm(Wi,p=1,dim=1)\n",
    "                inf_Wi = torch.max(Wi_inf)\n",
    "\n",
    "                if inf_Wi.data.cpu().numpy() >= (1-max_inf_f):\n",
    "                    \n",
    "                    model.lstm.weight_hh[0:64] = model.lstm.weight_hh[0:64].clone()/1.2\n",
    "\n",
    "                # inf norms of the LSTM Wf\n",
    "                Wf = model.lstm.weight_hh[64:128]\n",
    "                Wf_inf = torch.norm(Wf,p=1,dim=1)\n",
    "                inf_Wf = torch.max(Wf_inf)\n",
    "\n",
    "                if inf_Wf.data.cpu().numpy() >= pow((1-max_inf_f),2):\n",
    "                    model.lstm.weight_hh[64:128] = model.lstm.weight_hh[64:128].clone()/1.2\n",
    "\n",
    "                # inf norms of the LSTM Wz\n",
    "                Wz = model.lstm.weight_hh[128:192]\n",
    "                Wz_inf = torch.norm(Wz,p=1,dim=1)\n",
    "                inf_Wz = torch.max(Wz_inf)\n",
    "\n",
    "                if inf_Wz.data.cpu().numpy() >= 0.25*(1-max_inf_f):\n",
    "                    model.lstm.weight_hh[128:192] = model.lstm.weight_hh[128:192].clone()/1.2\n",
    "            \n",
    "\n",
    "            train_cnt +=1\n",
    "            if train_cnt%50 == 0:\n",
    "                correct_cnt = 0\n",
    "                total_cnt = 0\n",
    "                with torch.no_grad():\n",
    "                    for x, target in testloader:\n",
    "                        actor.multi_rollout(x.to(device),target.to(device),1)\n",
    "                        preds=actor.final_preds.to(device)\n",
    "                        _, pred_labels = torch.max(preds,1)\n",
    "                        correct_cnt += (pred_labels == target.to(device)).sum()\n",
    "                        total_cnt += pred_labels.shape[0]\n",
    "                    accuracy = correct_cnt.item() *1.0/(0.0+total_cnt) \n",
    "                    l_accuracy = accuracy\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                    #print result to file\n",
    "                    orig_stdout = sys.stdout\n",
    "                    f = open('mnist_log.txt', 'a+') \n",
    "                    sys.stdout = f\n",
    "                    print ('Epoch', epochs, 'time used', datetime.now()-old,'accuracy',l_accuracy, 'val',val.data.cpu().numpy())\n",
    "                    f.close()\n",
    "                    sys.stdout = orig_stdout\n",
    "\n",
    "    return best_accuracy,test_acc_lst\n",
    "\n",
    "def test(eps):\n",
    "    train_cnt = 0    \n",
    "    best_accuracy = 0\n",
    "    best_accuracy_train=0\n",
    "    test_acc_lst = []\n",
    "    old = datetime.now()\n",
    "    l_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for epochs in xrange(eps):\n",
    "            correct_cnt = 0\n",
    "            total_cnt = 0\n",
    "            for x, target in testloader:\n",
    "                actor.multi_rollout(x.to(device),target.to(device),1)\n",
    "                preds=actor.final_preds.to(device)\n",
    "                _, pred_labels = torch.max(preds,1)\n",
    "                correct_cnt += (pred_labels == target.to(device)).sum()\n",
    "                total_cnt += pred_labels.shape[0]\n",
    "            accuracy = correct_cnt.item() *1.0/(0.0+total_cnt) \n",
    "            l_accuracy = accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "            print ('Testing accuracy is ',accuracy)\n",
    "        \n",
    "    return best_accuracy,test_acc_lst\n",
    "\n",
    "time_h_list=[time_h] #[1,3,5,7,9,11]\n",
    "\n",
    "for time_h_counter in range(1):\n",
    "    time_h=time_h_list[time_h_counter]\n",
    "    \n",
    "    for k in range(1): \n",
    "        \n",
    "        model= CModel(HD=32, frame_size=f_size, n_agent=n_agent, _msg_dim=12, device=device, random_action_flag=False,no_channels=3,edge_pr=1,\\\n",
    "                              kern_size=1,model = vggm).to(device) # HD=64\n",
    "        \n",
    "        \n",
    "        env=EnvMNIST(x.to(device),target.to(device),n_agent=n_agent,seed=54,filter_size=f_size,device=device,max_dim=28)\n",
    "        actor = Actor(model,env,time_horizon=time_h,device=device)\n",
    "        \n",
    "        model.lstmcom_flag = False\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "        \n",
    "#         you can load the model using the following command\n",
    "#         model.load_state_dict(torch.load('mnist_multi.pt',map_location=device))\n",
    "\n",
    "        actor.random_action_flag = True\n",
    "\n",
    "#         First training stage, enabled for training with VGG and LSTM\n",
    "        mx, lst = train(300, optimizer, criterion)\n",
    "\n",
    "        actor.random_action_flag = False\n",
    "        \n",
    "        model.gn1.weight.requires_grad = True\n",
    "        model.gn1.bias.requires_grad = True\n",
    "        model.gp.weight.requires_grad = True\n",
    "        model.gp.bias.requires_grad = True\n",
    "        \n",
    "#         Second training stage, enabled for training with goals\n",
    "        mx, lst = train(200, optimizer, criterion)\n",
    "        \n",
    "#         Run this line to get the testing result, this line can be called multiple times \n",
    "#         test(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot movement history, square denotes the local obeservation, solid square denotes the goal position, and the green links\n",
    "# denotes the communication\n",
    "test(1)\n",
    "z = model.plot\n",
    "\n",
    "# change the index_to_play for different testing image\n",
    "index_to_play=65\n",
    "\n",
    "print (actor.final_preds[index_to_play],actor.env.targets[index_to_play]) \n",
    "\n",
    "actor.env.show_history(index_to_play)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 Anaconda",
   "language": "python",
   "name": "python2anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
